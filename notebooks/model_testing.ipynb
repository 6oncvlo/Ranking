{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa35c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gonpr\\ML_Projects\\Ranking\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import yaml\n",
    "import optuna\n",
    "\n",
    "from src.data.load import load_data\n",
    "from src.data.prepare import prepare_data\n",
    "from src.models.cv_iterator import leave_last_k\n",
    "from src.data.features import feature_engineering\n",
    "from src.data.utils import build_rank_input\n",
    "from src.models.tuner import BayesianSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbdb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('../config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader= yaml.SafeLoader)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3ceb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "dfs = load_data(config=config['data_loader'])\n",
    "dfs = prepare_data(dataframes=dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe7e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "df_train, df_test = leave_last_k(df=dfs['data'], config=config['optimization'])\n",
    "df_train, df_valid = leave_last_k(df=df_train, config=config['optimization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7335e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "442d5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.models.candidate import candidate_generation\n",
    "\n",
    "df_train_neg = candidate_generation(df_train, n=20+3*3+3*3, positive_sampling=False)\n",
    "df_test_neg = df_train_neg.groupby(by=['user_id']).sample(n=3*3)\n",
    "df_train_neg = df_train_neg.drop(df_test_neg.index)\n",
    "df_valid_neg = df_train_neg.groupby(by=['user_id']).sample(n=3*3)\n",
    "df_train_neg = df_train_neg.drop(df_valid_neg.index)\n",
    "\n",
    "df_train = pd.concat([df_train.iloc[:,:3], df_train_neg], ignore_index=True)\n",
    "df_valid = pd.concat([df_valid.iloc[:,:3], df_valid_neg], ignore_index=True)\n",
    "df_test = pd.concat([df_test.iloc[:,:3], df_test_neg], ignore_index=True)\n",
    "del df_train_neg, df_valid_neg, df_test_neg\n",
    "\n",
    "df_train, df_valid = [\n",
    "    build_rank_input(ratings=df, features=user_item_features) for df in (df_train, df_valid)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2fdc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 01:23:59,476] A new study created in memory with name: no-name-15f7b859-58e9-4b77-8b7f-9dce5a13bab2\n",
      "[I 2025-04-22 01:24:02,353] Trial 0 finished with value: 0.976741540618596 and parameters: {'learning_rate': 0.04908341003051759, 'gamma': 3.7065858092761146, 'max_depth': 6, 'subsample': 0.7062228902437528, 'n_estimators': 244}. Best is trial 0 with value: 0.976741540618596.\n",
      "[I 2025-04-22 01:24:05,303] Trial 1 finished with value: 0.9768793564633924 and parameters: {'learning_rate': 0.16719747105276128, 'gamma': 4.370416563761517, 'max_depth': 10, 'subsample': 0.9395825574976815, 'n_estimators': 285}. Best is trial 1 with value: 0.9768793564633924.\n",
      "[I 2025-04-22 01:24:06,540] Trial 2 finished with value: 0.9771345330861486 and parameters: {'learning_rate': 0.2046428502130527, 'gamma': 3.44540578166239, 'max_depth': 7, 'subsample': 0.6500770720456028, 'n_estimators': 70}. Best is trial 2 with value: 0.9771345330861486.\n",
      "[I 2025-04-22 01:24:09,615] Trial 3 finished with value: 0.9769635118723349 and parameters: {'learning_rate': 0.1763328770470147, 'gamma': 3.202506548919073, 'max_depth': 6, 'subsample': 0.6206145773092882, 'n_estimators': 298}. Best is trial 2 with value: 0.9771345330861486.\n",
      "[I 2025-04-22 01:24:11,070] Trial 4 finished with value: 0.976681290910245 and parameters: {'learning_rate': 0.0696325569200906, 'gamma': 3.770608651843545, 'max_depth': 10, 'subsample': 0.6433163293098441, 'n_estimators': 90}. Best is trial 2 with value: 0.9771345330861486.\n",
      "[I 2025-04-22 01:24:12,834] Trial 5 finished with value: 0.9767374482247965 and parameters: {'learning_rate': 0.12199629491444715, 'gamma': 3.7812942357126644, 'max_depth': 9, 'subsample': 0.7428415204861232, 'n_estimators': 122}. Best is trial 2 with value: 0.9771345330861486.\n",
      "[I 2025-04-22 01:24:15,807] Trial 6 finished with value: 0.977135679807928 and parameters: {'learning_rate': 0.19472901318311844, 'gamma': 3.365970454388793, 'max_depth': 3, 'subsample': 0.5438512066375949, 'n_estimators': 283}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:17,781] Trial 7 finished with value: 0.976558806537032 and parameters: {'learning_rate': 0.17550415444608952, 'gamma': 1.8753884513088115, 'max_depth': 5, 'subsample': 0.9076672555687741, 'n_estimators': 153}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:20,140] Trial 8 finished with value: 0.9767630799571309 and parameters: {'learning_rate': 0.10862297492672227, 'gamma': 3.357039107794056, 'max_depth': 9, 'subsample': 0.684022802607174, 'n_estimators': 200}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:23,204] Trial 9 finished with value: 0.9763369656197453 and parameters: {'learning_rate': 0.01310513072786032, 'gamma': 2.027707862136501, 'max_depth': 7, 'subsample': 0.7367241756815879, 'n_estimators': 231}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:25,523] Trial 10 finished with value: 0.9768921180879833 and parameters: {'learning_rate': 0.28647780714316606, 'gamma': 0.4673028876285623, 'max_depth': 3, 'subsample': 0.5187468102788967, 'n_estimators': 189}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:26,795] Trial 11 finished with value: 0.9767602643086805 and parameters: {'learning_rate': 0.2546395264841218, 'gamma': 4.67504492437366, 'max_depth': 3, 'subsample': 0.5255613848820812, 'n_estimators': 57}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:28,184] Trial 12 finished with value: 0.9771010531395742 and parameters: {'learning_rate': 0.22476669036266705, 'gamma': 2.6735092758946015, 'max_depth': 4, 'subsample': 0.8385033031790985, 'n_estimators': 51}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:30,671] Trial 13 finished with value: 0.9769278700325273 and parameters: {'learning_rate': 0.21581293468427343, 'gamma': 2.6363802389667965, 'max_depth': 7, 'subsample': 0.5941076897098927, 'n_estimators': 135}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:35,754] Trial 14 finished with value: 0.9765712673540967 and parameters: {'learning_rate': 0.21976405608196303, 'gamma': 0.8715014629657687, 'max_depth': 8, 'subsample': 0.5627400820659837, 'n_estimators': 252}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:37,936] Trial 15 finished with value: 0.9769134126547091 and parameters: {'learning_rate': 0.1368494496777799, 'gamma': 4.9594457403108265, 'max_depth': 5, 'subsample': 0.828320642407983, 'n_estimators': 97}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:42,408] Trial 16 finished with value: 0.9765663049484901 and parameters: {'learning_rate': 0.26513569565306233, 'gamma': 2.1494257273143242, 'max_depth': 5, 'subsample': 0.664786998948486, 'n_estimators': 213}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:46,333] Trial 17 finished with value: 0.976692138683075 and parameters: {'learning_rate': 0.20045005071812472, 'gamma': 1.3901542227436576, 'max_depth': 8, 'subsample': 0.5884112175974574, 'n_estimators': 154}. Best is trial 6 with value: 0.977135679807928.\n",
      "[I 2025-04-22 01:24:50,066] Trial 18 finished with value: 0.9774095374039995 and parameters: {'learning_rate': 0.24523622119359656, 'gamma': 4.295250678169682, 'max_depth': 4, 'subsample': 0.7976946755477082, 'n_estimators': 171}. Best is trial 18 with value: 0.9774095374039995.\n",
      "[I 2025-04-22 01:24:55,964] Trial 19 finished with value: 0.9770856094090722 and parameters: {'learning_rate': 0.2923691644586594, 'gamma': 4.274871286814266, 'max_depth': 4, 'subsample': 0.8262214229133569, 'n_estimators': 271}. Best is trial 18 with value: 0.9774095374039995.\n"
     ]
    }
   ],
   "source": [
    "# perform bayesian search\n",
    "searcher = BayesianSearch(config['optimization']['hyper_params'], algorithm='XGBRanker')\n",
    "\n",
    "def objective(trial) -> float:\n",
    "    return searcher.fit(df_train, df_valid, trial)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f0a664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "{'learning_rate': 0.24523622119359656, 'gamma': 4.295250678169682, 'max_depth': 4, 'subsample': 0.7976946755477082, 'n_estimators': 171}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9039a41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonpr\\AppData\\Local\\Temp\\ipykernel_25904\\2778080792.py:4: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  df_train = dfs['data'].merge(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# use indicator to know the origin\n",
    "df_train = dfs['data'].merge(\n",
    "    df_test\n",
    "    , on=['user_id', 'item_id', 'rating'], how='left'\n",
    "    , indicator=True\n",
    "    )\n",
    "# keep only rows that are present in df1 but not in df2\n",
    "df_train = df_train[df_train['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train}\n",
    "    )\n",
    "\n",
    "# add negative sampling\n",
    "df_train_neg = candidate_generation(df_train, n=20+3*3+3*3, positive_sampling=False)\n",
    "df_test_neg = df_train_neg.groupby(by=['user_id']).sample(n=3*3)\n",
    "df_train_neg = df_train_neg.drop(df_test_neg.index)\n",
    "\n",
    "df_train = pd.concat([df_train, df_train_neg], ignore_index=True)\n",
    "df_test = pd.concat([df_test, df_test_neg], ignore_index=True)\n",
    "\n",
    "\n",
    "df_train, df_test = [\n",
    "    build_rank_input(ratings=df.iloc[:,:3], features=user_item_features) for df in (df_train, df_test)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc255b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9809611013973318"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "from xgboost import XGBRanker\n",
    "import numpy as np\n",
    "\n",
    "clf = XGBRanker(**study.best_trial.params)\n",
    "clf.fit(\n",
    "    df_train['X'], df_train['y'].astype(int)\n",
    "    , group=df_train['group']\n",
    "    , verbose=False\n",
    "    )\n",
    "\n",
    "preds = clf.predict(df_test['X'])\n",
    "offset = 0\n",
    "ndcgs = []\n",
    "for group_size in df_test['group']:\n",
    "    y_true_group = df_test['y'][offset:offset+group_size]\n",
    "    preds_group = preds[offset:offset+group_size]\n",
    "    ndcgs.append(ndcg_score([y_true_group], [preds_group]))\n",
    "    offset += group_size\n",
    "np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acd12863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': [267, 1373],\n",
       " 'adventure': [50, 181, 300, 121, 174],\n",
       " 'animation': [50, 181, 174, 117, 172],\n",
       " 'children': [1, 71, 95, 588, 432],\n",
       " 'comedy': [1, 151, 423, 132, 71],\n",
       " 'crime': [294, 1, 204, 151, 173],\n",
       " 'documentary': [100, 127, 56, 302, 12],\n",
       " 'drama': [48, 32, 813, 847, 1065],\n",
       " 'fantasy': [258, 100, 286, 127, 56],\n",
       " 'film_noir': [423, 411, 472, 72, 755],\n",
       " 'horror': [302, 89, 654, 484, 657],\n",
       " 'musical': [288, 183, 234, 185, 200],\n",
       " 'mystery': [289, 186, 132, 143, 71],\n",
       " 'romance': [405, 302, 328, 191, 135],\n",
       " 'sci_fi': [50, 181, 286, 237, 172],\n",
       " 'thriller': [50, 258, 181, 121, 7],\n",
       " 'war': [100, 288, 300, 98, 117],\n",
       " 'western': [50, 181, 286, 121, 172],\n",
       " 'unknown': [97, 435, 203, 177, 73]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = dfs['data'].merge(\n",
    "    dfs['item'].drop(columns=['movie_title', 'release_date', 'imdb_url'])\n",
    "    , how='left', on='item_id'\n",
    "    )\n",
    "\n",
    "top_items_by_genre = {}\n",
    "\n",
    "# genre columns\n",
    "genre_cols = baseline.columns[4:]\n",
    "\n",
    "# loop over each genre\n",
    "for genre in genre_cols:\n",
    "    # filter ratings for movies that belong to this genre\n",
    "    genre_ratings = baseline[baseline[genre] == 1]\n",
    "    \n",
    "    # Count the number of ratings per item\n",
    "    top_items = (\n",
    "        genre_ratings\n",
    "        .groupby('item_id')\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(5)\n",
    "    )\n",
    "\n",
    "    # Save results\n",
    "    top_items_by_genre[genre] = list(top_items.index)\n",
    "\n",
    "top_items_by_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57bf480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonpr\\AppData\\Local\\Temp\\ipykernel_25904\\3909299453.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_genre_i.loc[:, 'item_id'] = [top_items_by_genre[genre]]* users_genre_i.shape[0]\n",
      "C:\\Users\\gonpr\\AppData\\Local\\Temp\\ipykernel_25904\\3909299453.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_genre_i.loc[:, 'item_id'] = [top_items_by_genre[genre]]* users_genre_i.shape[0]\n",
      "C:\\Users\\gonpr\\AppData\\Local\\Temp\\ipykernel_25904\\3909299453.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_genre_i.loc[:, 'item_id'] = [top_items_by_genre[genre]]* users_genre_i.shape[0]\n",
      "C:\\Users\\gonpr\\AppData\\Local\\Temp\\ipykernel_25904\\3909299453.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_genre_i.loc[:, 'item_id'] = [top_items_by_genre[genre]]* users_genre_i.shape[0]\n",
      "C:\\Users\\gonpr\\AppData\\Local\\Temp\\ipykernel_25904\\3909299453.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_genre_i.loc[:, 'item_id'] = [top_items_by_genre[genre]]* users_genre_i.shape[0]\n",
      "C:\\Users\\gonpr\\AppData\\Local\\Temp\\ipykernel_25904\\3909299453.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_genre_i.loc[:, 'item_id'] = [top_items_by_genre[genre]]* users_genre_i.shape[0]\n",
      "C:\\Users\\gonpr\\AppData\\Local\\Temp\\ipykernel_25904\\3909299453.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_genre_i.loc[:, 'item_id'] = [top_items_by_genre[genre]]* users_genre_i.shape[0]\n",
      "C:\\Users\\gonpr\\AppData\\Local\\Temp\\ipykernel_25904\\3909299453.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_genre_i.loc[:, 'item_id'] = [top_items_by_genre[genre]]* users_genre_i.shape[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9321982798478464, 793)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_genre_counts = baseline.groupby('user_id')[genre_cols].sum()\n",
    "\n",
    "# Get the genre with the max count per user\n",
    "user_genre = user_genre_counts.idxmax(axis=1).reset_index()\n",
    "user_genre.columns = ['user_id', 'genre']\n",
    "\n",
    "result = []\n",
    "\n",
    "for genre in top_items_by_genre.keys():\n",
    "    \n",
    "    users_genre_i = user_genre[user_genre['genre']==genre]\n",
    "    users_genre_i.loc[:, 'item_id'] = [top_items_by_genre[genre]]* users_genre_i.shape[0]\n",
    "    result.append(users_genre_i)\n",
    "\n",
    "result = (\n",
    "    pd.concat(result, axis=0, ignore_index=True)\n",
    "    .sort_values('user_id', ascending=True)\n",
    "    .reset_index(drop=True)\n",
    "    .drop(columns=['genre'])\n",
    "    )\n",
    "\n",
    "result.loc[:, 'est_rating'] = [list(range(5)[::-1])] * result.shape[0]\n",
    "result = result.explode(column=['item_id', 'est_rating'])\n",
    "result = result.merge(\n",
    "    dfs['data'][['user_id', 'item_id', 'rating']]\n",
    "    , how='left', on=['user_id', 'item_id']\n",
    ").dropna()\n",
    "\n",
    "group = result.groupby('user_id').size().to_list()\n",
    "\n",
    "offset = 0\n",
    "ndcgs = []\n",
    "len_gt1 = 0\n",
    "for group_size in group:\n",
    "    if group_size > 1:\n",
    "        len_gt1+=1\n",
    "        y_true_group = result['rating'][offset:offset+group_size]\n",
    "        preds_group = result['est_rating'][offset:offset+group_size]\n",
    "        ndcgs.append(ndcg_score([y_true_group], [preds_group]))\n",
    "        offset += group_size\n",
    "np.mean(ndcgs), len_gt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "032635c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9624581716775455"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline = build_rank_input(ratings=result.drop(columns=['est_rating']), features=user_item_features)\n",
    "\n",
    "preds = clf.predict(df_baseline['X'])\n",
    "offset = 0\n",
    "ndcgs = []\n",
    "for group_size in df_baseline['group']:\n",
    "    if group_size > 1:\n",
    "        y_true_group = np.array(df_baseline['y'][offset:offset+group_size], dtype=float)\n",
    "        preds_group = preds[offset:offset+group_size]\n",
    "        ndcgs.append(ndcg_score([y_true_group], [preds_group]))\n",
    "        offset += group_size\n",
    "np.mean(ndcgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa35c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gonpr\\ML_Projects\\Ranking\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import yaml\n",
    "import optuna\n",
    "\n",
    "from src.data.load import load_data\n",
    "from src.data.prepare import prepare_data\n",
    "from src.models.cv_iterator import leave_last_k\n",
    "from src.data.features import feature_engineering\n",
    "from src.data.utils import build_rank_input\n",
    "from src.models.tuner import BayesianSearch\n",
    "from src.models.evaluator import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbdb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('../config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader= yaml.SafeLoader)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3ceb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "dfs = load_data(config=config['data_loader'])\n",
    "dfs = prepare_data(dataframes=dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe7e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "df_train, df_test = leave_last_k(df=dfs['data'], config=config['optimization'])\n",
    "df_train, df_valid = leave_last_k(df=df_train, config=config['optimization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7335e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "442d5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.models.candidate import candidate_generation\n",
    "\n",
    "df_train_neg = candidate_generation(df_train, n=20, positive_sampling=False)\n",
    "df_train = pd.concat([df_train.iloc[:,:3], df_train_neg], ignore_index=True)\n",
    "\n",
    "del df_train_neg\n",
    "\n",
    "df_train, df_valid = [\n",
    "    build_rank_input(ratings=df.iloc[:,:3], features=user_item_features) for df in (df_train, df_valid)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2fdc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 17:07:44,938] A new study created in memory with name: no-name-d4ff19a1-dcbe-462c-bac2-b1fa72a4761c\n",
      "[I 2025-04-22 17:07:46,652] Trial 0 finished with value: 0.9476401245128002 and parameters: {'learning_rate': 0.13349069140524963, 'gamma': 4.711351684265544, 'max_depth': 8, 'subsample': 0.6127362974517998, 'n_estimators': 134}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:07:50,184] Trial 1 finished with value: 0.9454234372048969 and parameters: {'learning_rate': 0.029229768798753476, 'gamma': 0.0904263064921984, 'max_depth': 7, 'subsample': 0.8163199609056089, 'n_estimators': 240}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:07:53,182] Trial 2 finished with value: 0.9474871960760828 and parameters: {'learning_rate': 0.12808340444892047, 'gamma': 4.48086632682986, 'max_depth': 8, 'subsample': 0.9884290017913665, 'n_estimators': 289}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:07:55,051] Trial 3 finished with value: 0.9469939215153593 and parameters: {'learning_rate': 0.10763268239518037, 'gamma': 4.962551616546714, 'max_depth': 4, 'subsample': 0.5012520026608154, 'n_estimators': 166}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:07:56,132] Trial 4 finished with value: 0.9475055492083049 and parameters: {'learning_rate': 0.06339875748469685, 'gamma': 3.1008000652673218, 'max_depth': 3, 'subsample': 0.6363811684101182, 'n_estimators': 67}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:07:58,913] Trial 5 finished with value: 0.9443027577085007 and parameters: {'learning_rate': 0.21192071339337418, 'gamma': 0.6669125677544463, 'max_depth': 8, 'subsample': 0.9900451108512252, 'n_estimators': 272}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:08:01,446] Trial 6 finished with value: 0.9474138651447287 and parameters: {'learning_rate': 0.25167576526710084, 'gamma': 3.263453529810729, 'max_depth': 7, 'subsample': 0.5247498914466299, 'n_estimators': 263}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:08:03,662] Trial 7 finished with value: 0.9469857295712397 and parameters: {'learning_rate': 0.1587572056500247, 'gamma': 2.1668263746905936, 'max_depth': 6, 'subsample': 0.6581187402750391, 'n_estimators': 195}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:08:06,177] Trial 8 finished with value: 0.9474206706830267 and parameters: {'learning_rate': 0.17175538168369384, 'gamma': 2.6234665883440984, 'max_depth': 4, 'subsample': 0.9499549616907715, 'n_estimators': 254}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:08:09,110] Trial 9 finished with value: 0.9433597447637271 and parameters: {'learning_rate': 0.29804632651190904, 'gamma': 0.98910634918984, 'max_depth': 10, 'subsample': 0.5726904335538556, 'n_estimators': 236}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:08:10,609] Trial 10 finished with value: 0.9472756959739418 and parameters: {'learning_rate': 0.09046790424615224, 'gamma': 3.6999991319863614, 'max_depth': 10, 'subsample': 0.7974229843037647, 'n_estimators': 99}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:08:11,759] Trial 11 finished with value: 0.9457095274465291 and parameters: {'learning_rate': 0.04483872109548276, 'gamma': 3.985738919391201, 'max_depth': 5, 'subsample': 0.6703551949442306, 'n_estimators': 54}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:08:14,457] Trial 12 finished with value: 0.9476178277567106 and parameters: {'learning_rate': 0.06446309366577392, 'gamma': 2.2104205308677747, 'max_depth': 3, 'subsample': 0.6374479842361028, 'n_estimators': 113}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:08:17,990] Trial 13 finished with value: 0.9473306285934547 and parameters: {'learning_rate': 0.07700206637086998, 'gamma': 1.8468427747572456, 'max_depth': 9, 'subsample': 0.7390326082752197, 'n_estimators': 132}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:08:21,890] Trial 14 finished with value: 0.9453563654357636 and parameters: {'learning_rate': 0.01990648099962887, 'gamma': 1.6222734279080222, 'max_depth': 6, 'subsample': 0.5809257629498461, 'n_estimators': 139}. Best is trial 0 with value: 0.9476401245128002.\n",
      "[I 2025-04-22 17:08:25,031] Trial 15 finished with value: 0.9483659775090224 and parameters: {'learning_rate': 0.13031965305132584, 'gamma': 2.4746054762088905, 'max_depth': 3, 'subsample': 0.7104877097542801, 'n_estimators': 99}. Best is trial 15 with value: 0.9483659775090224.\n",
      "[I 2025-04-22 17:08:29,452] Trial 16 finished with value: 0.9471777672651706 and parameters: {'learning_rate': 0.18204760080694493, 'gamma': 2.817186681324002, 'max_depth': 8, 'subsample': 0.7339520895046635, 'n_estimators': 190}. Best is trial 15 with value: 0.9483659775090224.\n",
      "[I 2025-04-22 17:08:33,191] Trial 17 finished with value: 0.9468737921944348 and parameters: {'learning_rate': 0.1394817187973871, 'gamma': 3.775316759670064, 'max_depth': 5, 'subsample': 0.8813655316240698, 'n_estimators': 86}. Best is trial 15 with value: 0.9483659775090224.\n",
      "[I 2025-04-22 17:08:36,685] Trial 18 finished with value: 0.9459717979906055 and parameters: {'learning_rate': 0.213080100121946, 'gamma': 1.2475820426504203, 'max_depth': 9, 'subsample': 0.6905686887977066, 'n_estimators': 160}. Best is trial 15 with value: 0.9483659775090224.\n",
      "[I 2025-04-22 17:08:40,179] Trial 19 finished with value: 0.9472614015265105 and parameters: {'learning_rate': 0.11443619741185193, 'gamma': 4.65639967498382, 'max_depth': 5, 'subsample': 0.7892691646177781, 'n_estimators': 128}. Best is trial 15 with value: 0.9483659775090224.\n"
     ]
    }
   ],
   "source": [
    "# perform bayesian search\n",
    "searcher = BayesianSearch(config['optimization']['hyper_params'], algorithm='XGBRanker')\n",
    "\n",
    "def objective(trial) -> float:\n",
    "    return searcher.fit(df_train, df_valid, trial)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f0a664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "{'learning_rate': 0.13031965305132584, 'gamma': 2.4746054762088905, 'max_depth': 3, 'subsample': 0.7104877097542801, 'n_estimators': 99}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9039a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# use indicator to know the origin\n",
    "df_train = dfs['data'].merge(\n",
    "    df_test\n",
    "    , on=['user_id', 'item_id', 'rating'], how='left'\n",
    "    , indicator=True\n",
    "    )\n",
    "# keep only rows that are present in df1 but not in df2\n",
    "df_train = df_train[df_train['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train}\n",
    "    )\n",
    "\n",
    "# add negative sampling\n",
    "df_train_neg = candidate_generation(df_train, n=20, positive_sampling=False)\n",
    "df_train = pd.concat([df_train, df_train_neg], ignore_index=True)\n",
    "\n",
    "del df_train_neg\n",
    "\n",
    "df_train, df_test = [\n",
    "    build_rank_input(ratings=df.iloc[:,:3], features=user_item_features) for df in (df_train, df_test)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc255b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9531453590722662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "from xgboost import XGBRanker\n",
    "import numpy as np\n",
    "\n",
    "clf = XGBRanker(**study.best_trial.params)\n",
    "clf.fit(\n",
    "    df_train['X'], df_train['y'].astype(int)\n",
    "    , group=df_train['group']\n",
    "    , verbose=False\n",
    "    )\n",
    "\n",
    "preds = clf.predict(df_test['X'])\n",
    "\n",
    "print(evaluation(df_test['y'], preds, df_test['group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24edad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9168812846621082\n"
     ]
    }
   ],
   "source": [
    "from src.models.baseline import baseline_model\n",
    "\n",
    "result = baseline_model(dataframes=dfs, n=10)\n",
    "group = result.groupby('user_id').size().to_list()\n",
    "\n",
    "print(evaluation(result['rating'], result['est_rating'], group))\n",
    "del group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032635c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9499964153201759\n"
     ]
    }
   ],
   "source": [
    "user_item_features = feature_engineering(dataframes={\n",
    "    'user': dfs['user'], 'item': dfs['item'], 'data': dfs['data']\n",
    "    })\n",
    "\n",
    "df_baseline = build_rank_input(ratings=result.drop(columns=['est_rating']), features=user_item_features)\n",
    "\n",
    "preds = clf.predict(df_baseline['X'])\n",
    "print(evaluation(df_baseline['y'], preds, df_baseline['group']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa35c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import yaml\n",
    "import optuna\n",
    "\n",
    "from src.data.load import load_data\n",
    "from src.data.prepare import prepare_data\n",
    "from src.models.cv_iterator import leave_last_k\n",
    "from src.data.features import feature_engineering\n",
    "from src.data.utils import build_rank_input\n",
    "from src.models.tuner import BayesianSearch\n",
    "from src.models.evaluator import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbdb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('../config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader= yaml.SafeLoader)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3ceb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "dfs = load_data(config=config['data_loader'])\n",
    "dfs = prepare_data(dataframes=dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe7e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "df_train, df_test = leave_last_k(df=dfs['data'], config=config['optimization'])\n",
    "df_train, df_valid = leave_last_k(df=df_train, config=config['optimization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7335e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "442d5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.models.candidate import candidate_generation\n",
    "\n",
    "df_train_neg = candidate_generation(df_train, n=20, positive_sampling=False)\n",
    "df_train = pd.concat([df_train.iloc[:,:3], df_train_neg], ignore_index=True)\n",
    "\n",
    "del df_train_neg\n",
    "\n",
    "df_train, df_valid = [\n",
    "    build_rank_input(ratings=df.iloc[:,:3], features=user_item_features) for df in (df_train, df_valid)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2fdc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 19:22:57,419] A new study created in memory with name: no-name-54edbb6a-b853-47ba-8ece-1e03da917c37\n",
      "[I 2025-04-22 19:22:59,542] Trial 0 finished with value: 0.9474291287193659 and parameters: {'learning_rate': 0.23452112109053377, 'gamma': 4.870609588765207, 'max_depth': 4, 'subsample': 0.8835580872821923, 'n_estimators': 158}. Best is trial 0 with value: 0.9474291287193659.\n",
      "[I 2025-04-22 19:23:02,227] Trial 1 finished with value: 0.9468900543790266 and parameters: {'learning_rate': 0.078710564087631, 'gamma': 0.261141610098527, 'max_depth': 6, 'subsample': 0.5835749005927385, 'n_estimators': 171}. Best is trial 0 with value: 0.9474291287193659.\n",
      "[I 2025-04-22 19:23:04,754] Trial 2 finished with value: 0.9467646490442457 and parameters: {'learning_rate': 0.1856787036485623, 'gamma': 1.9013473969407624, 'max_depth': 10, 'subsample': 0.9980697997372148, 'n_estimators': 181}. Best is trial 0 with value: 0.9474291287193659.\n",
      "[I 2025-04-22 19:23:06,823] Trial 3 finished with value: 0.9436116572904123 and parameters: {'learning_rate': 0.010561892445558165, 'gamma': 0.690555304154376, 'max_depth': 8, 'subsample': 0.9839362357866588, 'n_estimators': 113}. Best is trial 0 with value: 0.9474291287193659.\n",
      "[I 2025-04-22 19:23:09,956] Trial 4 finished with value: 0.9450709038530647 and parameters: {'learning_rate': 0.279316176216521, 'gamma': 0.09044972872199686, 'max_depth': 9, 'subsample': 0.5960900477362119, 'n_estimators': 179}. Best is trial 0 with value: 0.9474291287193659.\n",
      "[I 2025-04-22 19:23:12,997] Trial 5 finished with value: 0.9470382601551743 and parameters: {'learning_rate': 0.2480914564410343, 'gamma': 4.751834782581686, 'max_depth': 3, 'subsample': 0.6474212519444438, 'n_estimators': 284}. Best is trial 0 with value: 0.9474291287193659.\n",
      "[I 2025-04-22 19:23:16,742] Trial 6 finished with value: 0.9464834479988092 and parameters: {'learning_rate': 0.10240665769068728, 'gamma': 0.9728967489187584, 'max_depth': 10, 'subsample': 0.5297142009893638, 'n_estimators': 258}. Best is trial 0 with value: 0.9474291287193659.\n",
      "[I 2025-04-22 19:23:18,380] Trial 7 finished with value: 0.9478601356446873 and parameters: {'learning_rate': 0.10494319240222902, 'gamma': 2.766921134314811, 'max_depth': 8, 'subsample': 0.7190042709343811, 'n_estimators': 102}. Best is trial 7 with value: 0.9478601356446873.\n",
      "[I 2025-04-22 19:23:19,737] Trial 8 finished with value: 0.9478374251575094 and parameters: {'learning_rate': 0.2590377610706838, 'gamma': 3.1506513778299454, 'max_depth': 4, 'subsample': 0.6437219818959166, 'n_estimators': 83}. Best is trial 7 with value: 0.9478601356446873.\n",
      "[I 2025-04-22 19:23:22,856] Trial 9 finished with value: 0.9460596253818508 and parameters: {'learning_rate': 0.02741685284584653, 'gamma': 1.2702732082321249, 'max_depth': 7, 'subsample': 0.805054786230373, 'n_estimators': 160}. Best is trial 7 with value: 0.9478601356446873.\n",
      "[I 2025-04-22 19:23:24,564] Trial 10 finished with value: 0.9468696022585077 and parameters: {'learning_rate': 0.13852839295881345, 'gamma': 3.1524594890539994, 'max_depth': 6, 'subsample': 0.7656939809742519, 'n_estimators': 58}. Best is trial 7 with value: 0.9478601356446873.\n",
      "[I 2025-04-22 19:23:26,014] Trial 11 finished with value: 0.9471335793285002 and parameters: {'learning_rate': 0.18493553385327813, 'gamma': 3.2514062232462675, 'max_depth': 5, 'subsample': 0.6910692460031962, 'n_estimators': 57}. Best is trial 7 with value: 0.9478601356446873.\n",
      "[I 2025-04-22 19:23:28,630] Trial 12 finished with value: 0.947050686501274 and parameters: {'learning_rate': 0.12902107685202327, 'gamma': 3.175651509644307, 'max_depth': 8, 'subsample': 0.7028876403403109, 'n_estimators': 93}. Best is trial 7 with value: 0.9478601356446873.\n",
      "[I 2025-04-22 19:23:31,545] Trial 13 finished with value: 0.9470387549997104 and parameters: {'learning_rate': 0.29531330850594467, 'gamma': 2.306272360048631, 'max_depth': 3, 'subsample': 0.8295199779132619, 'n_estimators': 111}. Best is trial 7 with value: 0.9478601356446873.\n",
      "[I 2025-04-22 19:23:33,918] Trial 14 finished with value: 0.9468872936869263 and parameters: {'learning_rate': 0.0648508623804036, 'gamma': 3.9687432789758113, 'max_depth': 5, 'subsample': 0.7017259544422252, 'n_estimators': 89}. Best is trial 7 with value: 0.9478601356446873.\n",
      "[I 2025-04-22 19:23:36,912] Trial 15 finished with value: 0.9473828752234009 and parameters: {'learning_rate': 0.18252232267129365, 'gamma': 3.919819239395287, 'max_depth': 7, 'subsample': 0.6234655285930091, 'n_estimators': 132}. Best is trial 7 with value: 0.9478601356446873.\n",
      "[I 2025-04-22 19:23:41,202] Trial 16 finished with value: 0.9480017341472744 and parameters: {'learning_rate': 0.2299459340918077, 'gamma': 2.534174904947987, 'max_depth': 8, 'subsample': 0.5477455410545349, 'n_estimators': 206}. Best is trial 16 with value: 0.9480017341472744.\n",
      "[I 2025-04-22 19:23:46,024] Trial 17 finished with value: 0.9479931954098653 and parameters: {'learning_rate': 0.2132888611118843, 'gamma': 1.882903131117031, 'max_depth': 8, 'subsample': 0.5022435294269921, 'n_estimators': 217}. Best is trial 16 with value: 0.9480017341472744.\n",
      "[I 2025-04-22 19:23:51,056] Trial 18 finished with value: 0.9463936413967615 and parameters: {'learning_rate': 0.21569152202345018, 'gamma': 1.6390517961283402, 'max_depth': 9, 'subsample': 0.5145314826420097, 'n_estimators': 223}. Best is trial 16 with value: 0.9480017341472744.\n",
      "[I 2025-04-22 19:23:59,398] Trial 19 finished with value: 0.9479513464985014 and parameters: {'learning_rate': 0.21948275025831146, 'gamma': 2.2111058514700503, 'max_depth': 9, 'subsample': 0.5532689613725742, 'n_estimators': 215}. Best is trial 16 with value: 0.9480017341472744.\n"
     ]
    }
   ],
   "source": [
    "# perform bayesian search\n",
    "searcher = BayesianSearch(config['optimization']['hyper_params'], algorithm='XGBRanker')\n",
    "\n",
    "def objective(trial) -> float:\n",
    "    return searcher.fit(df_train, df_valid, trial)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f0a664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "{'learning_rate': 0.2299459340918077, 'gamma': 2.534174904947987, 'max_depth': 8, 'subsample': 0.5477455410545349, 'n_estimators': 206}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9039a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# use indicator to know the origin\n",
    "df_train = dfs['data'].merge(\n",
    "    df_test\n",
    "    , on=['user_id', 'item_id', 'rating'], how='left'\n",
    "    , indicator=True\n",
    "    )\n",
    "# keep only rows that are present in df1 but not in df2\n",
    "df_train = df_train[df_train['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train}\n",
    "    )\n",
    "\n",
    "# add negative sampling\n",
    "df_train_neg = candidate_generation(df_train, n=20, positive_sampling=False)\n",
    "df_train = pd.concat([df_train, df_train_neg], ignore_index=True)\n",
    "\n",
    "del df_train_neg\n",
    "\n",
    "df_train, df_test = [\n",
    "    build_rank_input(ratings=df.iloc[:,:3], features=user_item_features) for df in (df_train, df_test)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc255b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9530592924293719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "from xgboost import XGBRanker\n",
    "import numpy as np\n",
    "\n",
    "clf = XGBRanker(**study.best_trial.params)\n",
    "clf.fit(\n",
    "    df_train['X'], df_train['y'].astype(int)\n",
    "    , group=df_train['group']\n",
    "    , verbose=False\n",
    "    )\n",
    "\n",
    "preds = clf.predict(df_test['X'])\n",
    "\n",
    "print(evaluation(df_test['y'], preds, df_test['group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24edad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9168812846621082\n"
     ]
    }
   ],
   "source": [
    "from src.models.baseline import baseline_model\n",
    "\n",
    "result = baseline_model(dataframes=dfs, n=10)\n",
    "group = result.groupby('user_id').size().to_list()\n",
    "\n",
    "print(evaluation(result['rating'], result['est_rating'], group))\n",
    "del group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032635c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9492278320090779\n"
     ]
    }
   ],
   "source": [
    "user_item_features = feature_engineering(dataframes={\n",
    "    'user': dfs['user'], 'item': dfs['item'], 'data': dfs['data']\n",
    "    })\n",
    "\n",
    "df_baseline = build_rank_input(ratings=result.drop(columns=['est_rating']), features=user_item_features)\n",
    "\n",
    "preds = clf.predict(df_baseline['X'])\n",
    "print(evaluation(df_baseline['y'], preds, df_baseline['group']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

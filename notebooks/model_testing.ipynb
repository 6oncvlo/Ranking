{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa35c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import yaml\n",
    "import optuna\n",
    "\n",
    "from src.data.load import load_data\n",
    "from src.data.prepare import prepare_data\n",
    "from src.models.cv_iterator import leave_last_k\n",
    "from src.data.features import feature_engineering\n",
    "from src.data.utils import build_rank_input\n",
    "from src.models.tuner import BayesianSearch\n",
    "from src.models.evaluator import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbdb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('../config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader= yaml.SafeLoader)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3ceb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "dfs = load_data(config=config['data_loader'])\n",
    "dfs = prepare_data(dataframes=dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe7e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "df_train, df_test = leave_last_k(df=dfs['data'], config=config['optimization'])\n",
    "df_train, df_valid = leave_last_k(df=df_train, config=config['optimization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7335e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "442d5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.models.candidate import candidate_generation\n",
    "\n",
    "df_train_neg = candidate_generation(df_train, n=30, positive_sampling=False)\n",
    "df_train_pos = candidate_generation(df_train, n=10, positive_sampling=True)\n",
    "df_train = pd.concat([df_train.iloc[:,:3], df_train_neg, df_train_pos], ignore_index=True)\n",
    "\n",
    "del df_train_neg, df_train_pos\n",
    "\n",
    "df_train, df_valid = [\n",
    "    build_rank_input(ratings=df.iloc[:,:3], features=user_item_features) for df in (df_train, df_valid)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2fdc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 23:20:03,017] A new study created in memory with name: no-name-89780b85-87c6-470f-a5cc-a01c3fe7b8bd\n",
      "[I 2025-04-24 23:20:04,627] Trial 0 finished with value: 0.9464535908838257 and parameters: {'learning_rate': 0.37078682433574506, 'gamma': 8.647628597752387, 'max_depth': 13, 'subsample': 0.9540068811041673, 'n_estimators': 100}. Best is trial 0 with value: 0.9464535908838257.\n",
      "[I 2025-04-24 23:20:08,760] Trial 1 finished with value: 0.947606967801189 and parameters: {'learning_rate': 0.0808506200535963, 'gamma': 6.299288726027914, 'max_depth': 12, 'subsample': 0.5225518754583722, 'n_estimators': 327}. Best is trial 1 with value: 0.947606967801189.\n",
      "[I 2025-04-24 23:20:10,809] Trial 2 finished with value: 0.946656103359856 and parameters: {'learning_rate': 0.24095828678445746, 'gamma': 8.664327458607922, 'max_depth': 13, 'subsample': 0.777121379390799, 'n_estimators': 135}. Best is trial 1 with value: 0.947606967801189.\n",
      "[I 2025-04-24 23:20:12,449] Trial 3 finished with value: 0.9468903251455778 and parameters: {'learning_rate': 0.2691144043656619, 'gamma': 4.114307732528594, 'max_depth': 4, 'subsample': 0.9410665868221876, 'n_estimators': 88}. Best is trial 1 with value: 0.947606967801189.\n",
      "[I 2025-04-24 23:20:18,702] Trial 4 finished with value: 0.9482575764173505 and parameters: {'learning_rate': 0.17423319195610582, 'gamma': 2.3067834016415834, 'max_depth': 4, 'subsample': 0.7242883370125134, 'n_estimators': 376}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:20:23,757] Trial 5 finished with value: 0.9467625143682291 and parameters: {'learning_rate': 0.27859865482248947, 'gamma': 7.954321241798078, 'max_depth': 3, 'subsample': 0.9242473907774404, 'n_estimators': 305}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:20:30,111] Trial 6 finished with value: 0.9478311987319362 and parameters: {'learning_rate': 0.23227155956860182, 'gamma': 1.3086310271869872, 'max_depth': 15, 'subsample': 0.7112218410518971, 'n_estimators': 378}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:20:33,860] Trial 7 finished with value: 0.9476053296178968 and parameters: {'learning_rate': 0.23332934959813623, 'gamma': 6.2825201952607586, 'max_depth': 14, 'subsample': 0.9467892575612873, 'n_estimators': 209}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:20:39,646] Trial 8 finished with value: 0.9470217078927868 and parameters: {'learning_rate': 0.2976668429191728, 'gamma': 9.381913182342863, 'max_depth': 11, 'subsample': 0.5674433503280893, 'n_estimators': 320}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:20:42,600] Trial 9 finished with value: 0.9456329554194524 and parameters: {'learning_rate': 0.29728141091556964, 'gamma': 9.455168505563144, 'max_depth': 8, 'subsample': 0.7437890827883866, 'n_estimators': 128}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:20:49,622] Trial 10 finished with value: 0.9460769848103016 and parameters: {'learning_rate': 0.06296001991311331, 'gamma': 0.04244355756677365, 'max_depth': 6, 'subsample': 0.6303891085732625, 'n_estimators': 233}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:21:00,912] Trial 11 finished with value: 0.9473579964960108 and parameters: {'learning_rate': 0.16025307378546028, 'gamma': 1.5645164056265097, 'max_depth': 9, 'subsample': 0.7257672456827217, 'n_estimators': 399}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:21:11,376] Trial 12 finished with value: 0.9471607967023394 and parameters: {'learning_rate': 0.4678129496923483, 'gamma': 2.3656990359329275, 'max_depth': 6, 'subsample': 0.8238789431211924, 'n_estimators': 391}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:21:17,518] Trial 13 finished with value: 0.947960472367689 and parameters: {'learning_rate': 0.14690001407798137, 'gamma': 2.999195031315858, 'max_depth': 10, 'subsample': 0.6519265317889005, 'n_estimators': 260}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:21:22,667] Trial 14 finished with value: 0.9480137766293727 and parameters: {'learning_rate': 0.13131741675820963, 'gamma': 3.6176501249479935, 'max_depth': 7, 'subsample': 0.6385990832178232, 'n_estimators': 254}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:21:26,235] Trial 15 finished with value: 0.9472063472432856 and parameters: {'learning_rate': 0.13456337095750076, 'gamma': 4.231892087121672, 'max_depth': 6, 'subsample': 0.8600793790994176, 'n_estimators': 173}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:21:31,648] Trial 16 finished with value: 0.9479191660924344 and parameters: {'learning_rate': 0.034940693407370535, 'gamma': 5.184199721572515, 'max_depth': 4, 'subsample': 0.6521654266203745, 'n_estimators': 278}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:21:37,240] Trial 17 finished with value: 0.9474308609175498 and parameters: {'learning_rate': 0.17398820898528555, 'gamma': 3.3889080200113075, 'max_depth': 7, 'subsample': 0.5945049161248259, 'n_estimators': 344}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:21:41,066] Trial 18 finished with value: 0.9426294351618232 and parameters: {'learning_rate': 0.0038232995257887203, 'gamma': 0.1561776924217133, 'max_depth': 5, 'subsample': 0.686408921151539, 'n_estimators': 189}. Best is trial 4 with value: 0.9482575764173505.\n",
      "[I 2025-04-24 23:21:45,858] Trial 19 finished with value: 0.9470219444678456 and parameters: {'learning_rate': 0.11099631078504232, 'gamma': 5.31727528638708, 'max_depth': 8, 'subsample': 0.799467888548768, 'n_estimators': 270}. Best is trial 4 with value: 0.9482575764173505.\n"
     ]
    }
   ],
   "source": [
    "# perform bayesian search\n",
    "searcher = BayesianSearch(config['optimization']['hyper_params'], algorithm='XGBRanker')\n",
    "\n",
    "def objective(trial) -> float:\n",
    "    return searcher.fit(df_train, df_valid, trial)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f0a664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "{'learning_rate': 0.17423319195610582, 'gamma': 2.3067834016415834, 'max_depth': 4, 'subsample': 0.7242883370125134, 'n_estimators': 376}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9039a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# use indicator to know the origin\n",
    "df_train = dfs['data'].merge(\n",
    "    df_test\n",
    "    , on=['user_id', 'item_id', 'rating'], how='left'\n",
    "    , indicator=True\n",
    "    )\n",
    "# keep only rows that are present in df1 but not in df2\n",
    "df_train = df_train[df_train['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train}\n",
    "    )\n",
    "\n",
    "# add negative sampling\n",
    "df_train_neg = candidate_generation(df_train, n=20, positive_sampling=False)\n",
    "df_train_pos = candidate_generation(df_train, n=20, positive_sampling=False)\n",
    "df_train_ = pd.concat([df_train, df_train_neg, df_train_pos], ignore_index=True)\n",
    "\n",
    "del df_train_neg, df_train_pos\n",
    "\n",
    "df_train_, df_test_ = [\n",
    "    build_rank_input(ratings=df.iloc[:,:3], features=user_item_features) for df in (df_train_, df_test)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc255b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9531686718041839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "from xgboost import XGBRanker\n",
    "import numpy as np\n",
    "\n",
    "clf = XGBRanker(**study.best_trial.params)\n",
    "clf.fit(\n",
    "    df_train_['X'], df_train_['y'].astype(int)\n",
    "    , group=df_train_['group']\n",
    "    , verbose=False\n",
    "    )\n",
    "\n",
    "preds = clf.predict(df_test_['X'])\n",
    "\n",
    "print(evaluation(df_test_['y'], preds, df_test_['group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c053c1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.6463195691202872\n",
      "Novelty: 0.9984584266355963\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(top_items, data):\n",
    "    # Coverage: proportion of unique items recommended\n",
    "    recommended_items = top_items['item_id'].unique()\n",
    "    total_items = data['item_id'].unique()\n",
    "    coverage_score = len(recommended_items) / len(total_items)\n",
    "    \n",
    "    # Novelty: Based on item popularity (inverse)\n",
    "    item_popularity = data.groupby('item_id').size()\n",
    "    item_popularity = item_popularity[item_popularity > 0]\n",
    "    item_popularity = 1 - item_popularity / item_popularity.sum()  # Normalize\n",
    "    novelty_score = top_items['item_id'].map(item_popularity).mean()\n",
    "\n",
    "    return coverage_score, novelty_score\n",
    "\n",
    "# Calculate metrics for the recommendations\n",
    "coverage_score, novelty_score = calculate_metrics(df_test.iloc[:, :2], df_train.iloc[:, :3])\n",
    "# Print out the results\n",
    "print(f'Coverage: {coverage_score}')\n",
    "print(f'Novelty: {novelty_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24edad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9168812846621082\n"
     ]
    }
   ],
   "source": [
    "from src.models.baseline import baseline_model\n",
    "\n",
    "result = baseline_model(dataframes=dfs, n=10)\n",
    "group = result.groupby('user_id').size().to_list()\n",
    "\n",
    "print(evaluation(result['rating'], result['est_rating'], group))\n",
    "del group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "032635c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9494141491923237\n"
     ]
    }
   ],
   "source": [
    "user_item_features = feature_engineering(dataframes={\n",
    "    'user': dfs['user'], 'item': dfs['item'], 'data': dfs['data']\n",
    "    })\n",
    "\n",
    "df_baseline = build_rank_input(ratings=result.drop(columns=['est_rating']), features=user_item_features)\n",
    "\n",
    "preds = clf.predict(df_baseline['X'])\n",
    "print(evaluation(df_baseline['y'], preds, df_baseline['group']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

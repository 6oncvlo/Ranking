{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa35c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from src.data.load import load_data\n",
    "from src.data.prepare import prepare_data\n",
    "from src.models.cv_iterator import leave_last_k\n",
    "from src.features.features import feature_engineering\n",
    "from src.models.retrieval import candidate_generation\n",
    "from src.features.utils import build_rank_input\n",
    "from src.models.ranker import Ranker\n",
    "from src.models.baseline import baseline_model\n",
    "from src.models.evaluator import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbdb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('..\\main\\config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader= yaml.SafeLoader)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3ceb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "dfs = load_data(config=config['data_loader'])\n",
    "dfs = prepare_data(dataframes=dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7335e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate candidates through negative sampling\n",
    "candidates = candidate_generation(dfs['data'], config['model']['retrieval'])\n",
    "df_train = pd.concat(\n",
    "    [dfs['data'].iloc[:,:3], candidates['positive'], candidates['negative']]\n",
    "    , ignore_index=True\n",
    "    )\n",
    "\n",
    "# build features for ranking model\n",
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train})\n",
    "df_train = build_rank_input(ratings=df_train, features=user_item_features)\n",
    "\n",
    "del candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b45f1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ranking model\n",
    "clf = Ranker(\n",
    "    algorithm='XGBRanker',\n",
    "    params=config['model']['ranking']['hyper_params']\n",
    "    )\n",
    "clf.fit(\n",
    "    df_train['X'], df_train['y']\n",
    "    , group=df_train['group']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2975206",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf.model, f'../{config[\"model\"][\"path\"]}')\n",
    "del clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58389de7",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "- Get candidates thorugh anti-train set\n",
    "- Rank candidates and get top-k recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7fc863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(f'../{config[\"model\"][\"path\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4203197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a full user-item cartesian product (all possible interactions)\n",
    "all_user_item_pairs = pd.MultiIndex.from_product(\n",
    "    [dfs['data']['user_id'].unique(), dfs['data']['item_id'].unique()]\n",
    "    , names=['user_id', 'item_id']\n",
    "    ).to_frame(index=False)\n",
    "\n",
    "# merge with actual ratings to find which ones exist\n",
    "all_user_item_pairs = all_user_item_pairs.merge(\n",
    "    dfs['data'][['user_id', 'item_id']].copy()\n",
    "    , on=['user_id', 'item_id'], how='left', indicator=True\n",
    "    )\n",
    "\n",
    "# filter out existing ratings and select user-item pairs\n",
    "candidates = all_user_item_pairs[all_user_item_pairs['_merge'] == 'left_only']\n",
    "candidates = candidates[['user_id', 'item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "766be8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179426</th>\n",
       "      <td>1</td>\n",
       "      <td>1467</td>\n",
       "      <td>3.271719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179369</th>\n",
       "      <td>1</td>\n",
       "      <td>1599</td>\n",
       "      <td>3.263664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179243</th>\n",
       "      <td>1</td>\n",
       "      <td>1293</td>\n",
       "      <td>3.256404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355914</th>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>2.667152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356402</th>\n",
       "      <td>2</td>\n",
       "      <td>1467</td>\n",
       "      <td>2.574783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356345</th>\n",
       "      <td>2</td>\n",
       "      <td>1599</td>\n",
       "      <td>2.566728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421129</th>\n",
       "      <td>3</td>\n",
       "      <td>851</td>\n",
       "      <td>-0.464762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id      pred\n",
       "179426        1     1467  3.271719\n",
       "179369        1     1599  3.263664\n",
       "179243        1     1293  3.256404\n",
       "355914        2     1500  2.667152\n",
       "356402        2     1467  2.574783\n",
       "356345        2     1599  2.566728\n",
       "421129        3      851 -0.464762"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add user-item features\n",
    "candidates = (\n",
    "    candidates\n",
    "    .merge(user_item_features['user'], how='left', on='user_id')\n",
    "    .merge(user_item_features['item'], how='left', on='item_id')\n",
    "    )\n",
    "\n",
    "# rank and get top-k items\n",
    "candidates['pred'] = clf.predict(candidates.drop(columns=['user_id', 'item_id']))\n",
    "(\n",
    "    candidates\n",
    "    .sort_values(['user_id', 'pred'], ascending=[True, False])\n",
    "    .groupby('user_id').head(3)\n",
    "    [['user_id', 'item_id', 'pred']]\n",
    "    .head(7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89efc9c7",
   "metadata": {},
   "source": [
    "**Baseline Model**\n",
    "- Compare baseline vs ranking model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c164e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model: 0.9169\n",
      "Ranking model: 0.9531\n"
     ]
    }
   ],
   "source": [
    "# get recommendations based on popularity\n",
    "df_baseline = baseline_model(dataframes=dfs, n=10)\n",
    "group = df_baseline.groupby('user_id').size().to_list()\n",
    "\n",
    "print(\n",
    "    f\"Baseline model: {evaluation(df_baseline['rating'], df_baseline['est_rating'], group):.4f}\"\n",
    "    )\n",
    "del group\n",
    "\n",
    "# get model's ranking and compute accuracy\n",
    "df_baseline = build_rank_input(\n",
    "    ratings=df_baseline.drop(columns=['est_rating']),\n",
    "    features=user_item_features\n",
    "    )\n",
    "\n",
    "preds = clf.predict(df_baseline['X'])\n",
    "print(\n",
    "    f\"Ranking model: {evaluation(df_baseline['y'], preds, df_baseline['group']):.4f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
